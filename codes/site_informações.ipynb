{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s19P_OZZX1Rm"
      },
      "source": [
        "# pips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSkdnM_umIY0",
        "outputId": "f2fc3fb7-ac7c-4147-8deb-863e3a9d06d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /workspaces/SynaptaInvest/venv/lib/python3.10/site-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /workspaces/SynaptaInvest/venv/lib/python3.10/site-packages (4.12.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/SynaptaInvest/venv/lib/python3.10/site-packages (from requests) (2024.7.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/SynaptaInvest/venv/lib/python3.10/site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /workspaces/SynaptaInvest/venv/lib/python3.10/site-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/SynaptaInvest/venv/lib/python3.10/site-packages (from requests) (1.26.19)\n",
            "Requirement already satisfied: soupsieve>1.2 in /workspaces/SynaptaInvest/venv/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xQmoMMg0sHy",
        "outputId": "d4f46b5b-9443-4113-c0a0-60afc34b67c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement LinkedinProfile (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for LinkedinProfile\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install LinkedinProfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk5iK22ipQ9P",
        "outputId": "7ac0134a-aa64-49d7-fe0a-1803306f6a2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting trafilatura\n",
            "  Downloading trafilatura-1.12.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: certifi in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from trafilatura) (2024.7.4)\n",
            "Collecting courlan>=1.2.0 (from trafilatura)\n",
            "  Downloading courlan-1.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting htmldate>=1.8.1 (from trafilatura)\n",
            "  Downloading htmldate-1.8.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting justext>=3.0.1 (from trafilatura)\n",
            "  Downloading jusText-3.0.1-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting lxml>=5.2.2 (from trafilatura)\n",
            "  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: charset-normalizer>=3.2.0 in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from trafilatura) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from trafilatura) (2.2.2)\n",
            "Collecting babel>=2.15.0 (from courlan>=1.2.0->trafilatura)\n",
            "  Downloading babel-2.16.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tld>=0.13 (from courlan>=1.2.0->trafilatura)\n",
            "  Downloading tld-0.13-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting dateparser>=1.1.2 (from htmldate>=1.8.1->trafilatura)\n",
            "  Downloading dateparser-1.2.0-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from htmldate>=1.8.1->trafilatura) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura) (2024.1)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura) (2024.7.24)\n",
            "Collecting tzlocal (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura)\n",
            "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting lxml-html-clean (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura)\n",
            "  Downloading lxml_html_clean-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->htmldate>=1.8.1->trafilatura) (1.16.0)\n",
            "Downloading trafilatura-1.12.0-py3-none-any.whl (130 kB)\n",
            "Downloading courlan-1.3.0-py3-none-any.whl (33 kB)\n",
            "Downloading htmldate-1.8.1-py3-none-any.whl (31 kB)\n",
            "Downloading jusText-3.0.1-py2.py3-none-any.whl (837 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.8/837.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading babel-2.16.0-py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
            "Downloading tld-0.13-py2.py3-none-any.whl (263 kB)\n",
            "Downloading lxml_html_clean-0.2.0-py3-none-any.whl (13 kB)\n",
            "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: tzlocal, tld, lxml, babel, lxml-html-clean, dateparser, courlan, htmldate, justext, trafilatura\n",
            "Successfully installed babel-2.16.0 courlan-1.3.0 dateparser-1.2.0 htmldate-1.8.1 justext-3.0.1 lxml-5.3.0 lxml-html-clean-0.2.0 tld-0.13 trafilatura-1.12.0 tzlocal-5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install trafilatura\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpfMBIrEqQtH",
        "outputId": "3f86c579-d1b2-4d72-8e97-06d497fc2ecd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (2.32.3)\n",
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from requests) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from requests) (2024.7.4)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
            "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
            "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: soupsieve, beautifulsoup4\n",
            "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.6\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /workspaces/SynaptaInvest/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (4.44.2)\n",
            "Collecting trafilatura\n",
            "  Downloading trafilatura-1.12.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: filelock in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from transformers) (2.1.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from transformers) (2024.7.24)\n",
            "Requirement already satisfied: requests in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: certifi in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from trafilatura) (2024.8.30)\n",
            "Collecting courlan>=1.2.0 (from trafilatura)\n",
            "  Downloading courlan-1.3.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting htmldate>=1.8.1 (from trafilatura)\n",
            "  Downloading htmldate-1.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting justext>=3.0.1 (from trafilatura)\n",
            "  Downloading jusText-3.0.1-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting lxml>=5.2.2 (from trafilatura)\n",
            "  Downloading lxml-5.3.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: charset-normalizer>=3.2.0 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from trafilatura) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from trafilatura) (2.2.2)\n",
            "Collecting babel>=2.16.0 (from courlan>=1.2.0->trafilatura)\n",
            "  Downloading babel-2.16.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tld>=0.13 (from courlan>=1.2.0->trafilatura)\n",
            "  Downloading tld-0.13-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting dateparser>=1.1.2 (from htmldate>=1.8.1->trafilatura)\n",
            "  Downloading dateparser-1.2.0-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from htmldate>=1.8.1->trafilatura) (2.9.0.post0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: pytz in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura) (2024.1)\n",
            "Collecting tzlocal (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura)\n",
            "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting lxml-html-clean (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura)\n",
            "  Downloading lxml_html_clean-0.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->htmldate>=1.8.1->trafilatura) (1.16.0)\n",
            "Downloading trafilatura-1.12.2-py3-none-any.whl (132 kB)\n",
            "Downloading courlan-1.3.1-py3-none-any.whl (33 kB)\n",
            "Downloading htmldate-1.9.0-py3-none-any.whl (31 kB)\n",
            "Downloading jusText-3.0.1-py2.py3-none-any.whl (837 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.8/837.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml-5.3.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading babel-2.16.0-py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
            "Downloading tld-0.13-py2.py3-none-any.whl (263 kB)\n",
            "Downloading lxml_html_clean-0.2.2-py3-none-any.whl (13 kB)\n",
            "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: tzlocal, tld, lxml, babel, lxml-html-clean, dateparser, courlan, htmldate, justext, trafilatura\n",
            "Successfully installed babel-2.16.0 courlan-1.3.1 dateparser-1.2.0 htmldate-1.9.0 justext-3.0.1 lxml-5.3.0 lxml-html-clean-0.2.2 tld-0.13 trafilatura-1.12.2 tzlocal-5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers trafilatura\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tkT2k8lX5QX"
      },
      "source": [
        "# codigo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSI2jvntmQ7z",
        "outputId": "dfe51405-7122-4f0e-c48a-5f30e33c69b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/workspaces/SynaptaInvest/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Your max_length is set to 512, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
            "Your max_length is set to 512, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
            "Your max_length is set to 512, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
            "Your max_length is set to 512, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
            "Your max_length is set to 512, but your input_length is only 459. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=229)\n",
            "Your max_length is set to 512, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
            "Your max_length is set to 512, but your input_length is only 429. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=214)\n",
            "Your max_length is set to 512, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
            "Your max_length is set to 512, but your input_length is only 449. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=224)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            news_text\n",
            "0   Abertura econômica é caminho para desenvolvime...\n",
            "1   [Removed]\\nPágina de conteúdo da pálina. Erro ...\n",
            "2   [Removed]\\nPágina de conteúdo da pálina. Erro ...\n",
            "3   [Removed]\\nPágina de conteúdo da pálina. Erro ...\n",
            "4   Mais política industrial verde\\nA demanda por ...\n",
            "5   Alguém está ouvindo o que diz a Ciência?\\nErro...\n",
            "6   Alto Escalão: VR troca de comando\\nSimone Marq...\n",
            "7   Tecnologia como ferramenta de concretização do...\n",
            "8   Ouribank oferece crédito para empresas para o ...\n",
            "9   Ouribank oferece crédito para empresas para o ...\n",
            "10  Post mente ao dizer que Starlink detém todos o...\n",
            "11  Brasil desenha proposta para atrair investimen...\n",
            "12  Brasil desenha proposta para atrair investimen...\n",
            "13  Ecossistema do BB, BNDES e Itaúsa para investi...\n",
            "14  Dexco obtém US$ 1 bilhão em financiamento para...\n",
            "15  CDBs: prefixados e pós-fixados em movimentos o...\n",
            "16  Starlink não é dona de todos os satélites do B...\n",
            "17  “A diversidade acrescenta valor”\\nErro ao resu...\n",
            "18  Bets: cresce número de brasileiros que pegam e...\n",
            "19  Fiagro: a dinâmica e os maiores retornos em 20...\n",
            "20  Itaú (ITUB4) ou Itaúsa (ITSA4): qual paga mais...\n",
            "21  Linklaters assessora Africa Finance Corporatio...\n",
            "22  Fundador e ex-CEO da Raize junta-se ao Novo Ba...\n",
            "23  Ex-CEO e fundador da Raize vai liderar área de...\n",
            "24  Pix por aproximação está cada vez mais próximo...\n",
            "25  Pix por aproximação está mais próximo da reali...\n",
            "26  Open finance vai facilitar o Pix por aproximaç...\n",
            "27  Pix por aproximação mais próximo da realidade\\...\n",
            "28  Em fase de 'amadurecimento', transferências in...\n",
            "29  China não tem rivais quando o assunto são mega...\n",
            "30  CVM publica normas para portabilidade de inves...\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
            "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
            "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
            "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import trafilatura\n",
        "from transformers import pipeline\n",
        "import time\n",
        "\n",
        "# Caminho para o arquivo CSV\n",
        "file_path = './database/finance_news.csv'\n",
        "\n",
        "# Carrega o arquivo CSV em um DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "def extrair_texto_principal(url):\n",
        "    try:\n",
        "        # Baixar e extrair o texto principal da URL\n",
        "        downloaded = trafilatura.fetch_url(url)\n",
        "        if downloaded:\n",
        "            texto_principal = trafilatura.extract(downloaded, output_format='txt')\n",
        "            if texto_principal:\n",
        "                return texto_principal\n",
        "            else:\n",
        "                return \"Não foi possível encontrar o conteúdo principal.\"\n",
        "        else:\n",
        "            return \"Erro ao baixar o conteúdo da página.\"\n",
        "    except Exception as e:\n",
        "        return f\"Erro ao extrair texto de {url}: {e}\"\n",
        "\n",
        "# Inicializa o pipeline de summarization do Hugging Face\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "def resumir_texto(texto, max_len=512, min_len=20):\n",
        "    try:\n",
        "        # Gera o resumo com comprimento ajustável\n",
        "        resumo = summarizer(texto, max_length=max_len, min_length=min_len, do_sample=False)\n",
        "        return resumo[0]['summary_text']\n",
        "    except Exception as e:\n",
        "        return f\"Erro ao resumir o texto: {e}\"\n",
        "\n",
        "# Extrai a coluna 'links' e 'title' e converte para listas\n",
        "urls = df['link'].tolist()\n",
        "titles = df['title'].tolist()\n",
        "\n",
        "# Lista para armazenar os dados da nova tabela\n",
        "data = []\n",
        "\n",
        "for title, url in zip(titles, urls):\n",
        "    texto_completo = extrair_texto_principal(url)  # Extrai o texto principal da URL\n",
        "    resumo_texto = resumir_texto(texto_completo, max_len=512, min_len=200)  # Ajusta o comprimento do resumo\n",
        "    texto_final = f'{title}\\n{resumo_texto}'  # Concatena o título com o resumo\n",
        "    data.append({'news_text': texto_final})\n",
        "    time.sleep(1)  # Espera 1 segundo entre as requisições\n",
        "\n",
        "# Cria um novo DataFrame com os dados processados\n",
        "df_final = pd.DataFrame(data, columns=['news_text'])\n",
        "\n",
        "# Exibe a tabela final\n",
        "print(df_final)\n",
        "\n",
        "# Salvar a tabela em um novo arquivo CSV, se necessário\n",
        "df_final.to_csv('./database/news_texts.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
